# -*- coding: utf-8 -*-
"""Kurniati LM_Proyek Pertama : Membuat Model NLP dengan TensorFlow.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1vkWuhD_jYHYIVinIXMTFqceXxJClXbgQ
"""

""" Impor Data Set dan Pemrosesan Awal"""

import pandas as pd

# Membaca dataset awal
df = pd.read_json('News_Category_Dataset_v3.json', lines=True)
df.head()

# Mengecek dataset awal
df.info()

# Menghapus kolom link, short_description, authors, dan date dari dataset awal sehingga dataset hanya berisi headline dan category
df = df.drop(columns=['link', 'short_description', 'authors', 'date'])
df.head()

# Menghitung jumlah data headline dari masing-masing category
df['category'].value_counts()

# Membuat news_df sebagai dataset dengan category Sports, Food & Drink, dan Crime yang akan digunakan pada proyek.
news_df= df[df["category"].isin(['SPORTS', 'FOOD & DRINK', 'CRIME'])].reset_index()
news_df.head()

# Mengecek jumlah dan tipe data news_df
news_df.info()

# Menghitung jumlah data headline news_df dari masing-masing category
news_df['category'].value_counts()



""" Pemrosesan Lanjutan Data untuk Machine Learning """
#  One-hot-encoding untuk data kategorikal dan membuat dataframe baru.
category = pd.get_dummies(news_df.category)
news_new = pd.concat([news_df, category], axis=1)
news_new = news_new.drop(columns='category')
news_new

# Mengubah nilai-nilai dari dataframe ke dalam tipe data numpy array menggunakan atribut values.

headline = news_new['headline'].values
category = news_new[[ 'SPORTS', 'FOOD & DRINK', 'CRIME']].values

#Membagi data menjadi 80% data training dan 20% data validation dengan menggunakan test_size 0.2

from sklearn.model_selection import train_test_split
headline_train, headline_val, category_train, category_val = train_test_split(headline, category, test_size=0.2)



""" Tokenisasi headline """
# Tokenisasi dan mengubahnya setiap sample jadi sekuens
from tensorflow.keras.preprocessing.text import Tokenizer
from tensorflow.keras.preprocessing.sequence import pad_sequences

# Mengartikan masing-masing kata menjadi token
tokenizer = Tokenizer(num_words=90000, oov_token='x')
tokenizer.fit_on_texts(headline_train)

# Menerapkan token ke data headline dan mengubahnya menjadi sekuens token
sekuens_train = tokenizer.texts_to_sequences(headline_train)
sekuens_val = tokenizer.texts_to_sequences(headline_val)

# Merapikan sekuens hasil tokenisasi
padded_train = pad_sequences(sekuens_train, padding='post', maxlen=25, truncating='post')
padded_val = pad_sequences(sekuens_val, padding='post', maxlen=25, truncating='post')


"""" Membuat dan Menguji Model Machine Learning menggunakan library TensorFlow """
# Membuat model Sekuensial
import tensorflow as tf
model = tf.keras.Sequential([
    tf.keras.layers.Embedding(input_dim=90000, output_dim=25),
    tf.keras.layers.LSTM(256),
    tf.keras.layers.Dense(1024, activation='relu'),
    tf.keras.layers.Dropout(rate=0.4),
    tf.keras.layers.Dense(512, activation='relu'),
    tf.keras.layers.Dropout(rate=0.4),
    tf.keras.layers.Dense(256, activation='relu'),
    tf.keras.layers.Dropout(rate=0.4),
    tf.keras.layers.Dense(128, activation='relu'),
    tf.keras.layers.Dropout(rate=0.4),
    tf.keras.layers.Dense(64, activation='relu'),
    tf.keras.layers.Dropout(rate=0.4),
    tf.keras.layers.Dense(3, activation='softmax')
])

# Model Compile untuk multiclass categorical
model.compile(loss='categorical_crossentropy',optimizer='Nadam',metrics=['accuracy'])

# Membuat class callback
class myCallback(tf.keras.callbacks.Callback):
  def on_epoch_end(self, epoch, logs={}):
    if(logs.get('accuracy')>0.90 and logs.get('val_accuracy')>0.90):
      print("\nAkurasi telah mencapai >90%!")
      self.model.stop_training = True
callbacks = myCallback()

# Model Fit
history = model.fit(padded_train, category_train, epochs=50,
                    validation_data= (padded_val, category_val), callbacks=[callbacks], verbose=2)

# Menampilkan Grafik
import matplotlib.pyplot as plt
# Grafik Akurasi
plt.plot(history.history['accuracy'])
plt.plot(history.history['val_accuracy'])
plt.title('Akurasi Model NLP Kategori Headline Berita')
plt.ylabel('accuracy')
plt.xlabel('epoch')
plt.ylim(ymin=0)
plt.legend(['train', 'validation'], loc='upper left')
plt.show()

# Grafik Loss
plt.plot(history.history['loss'])
plt.plot(history.history['val_loss'])
plt.title('Loss Model NLP Kategori Headline Berita')
plt.ylabel('loss')
plt.xlabel('epoch')
plt.legend(['train', 'validation'], loc='upper left')
plt.show()

